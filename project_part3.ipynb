{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Goal and Significance\n",
    "\n",
    "### Goal\n",
    "\n",
    "The objective of Part 3 of this project is to **predict** a specific customer's product rating by leveraging **user intrinsic characteristics** (e.g., skin tone, skin type, hair color, total negative feedback count, total positive feedback count, etc.) and **product features** (e.g., product name, loves count, average rating, etc.). We also plan to analyze which features contribute most to product ratings, providing meaningful insights into customer preferences and product considerations.\n",
    "\n",
    "### Significance\n",
    "This project holds value in several key areas:\n",
    "1. **Personalized Recommendations**: Enables tailored product suggestions by leveraging customer and product attributes, enhancing user experience.\n",
    "2. **Improved Customer Satisfaction**: Delivers actionable insights to meet individual preferences more effectively.\n",
    "3. **Business Insights**: Helps businesses identify features that drive satisfaction, informing product improvements and marketing strategies.\n",
    "4. **Advancing E-commerce AI**: Demonstrates the power of predictive modeling in improving decision-making and engagement within e-commerce platforms.\n",
    "\n",
    "In summary, this project not only enhances user satisfaction but also deepens our understanding of consumer behavior and product performance, bridging the gap between data-driven technology and personalized service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "\n",
    "In this step, we plan to import and preprocess the data for future usage. This includes handling missing values, extracting relevant features, and merging datasets to create a comprehensive dataframe for analysis. The preprocessing steps ensure that the data is clean and ready for modeling and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "product_df = pd.read_csv(\"Sephora/product_info.csv\")\n",
    "print(\"product info dataframe shape: \", product_df.shape)\n",
    "product_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.kaggle.com/code/themeeemul/sephora-eda-and-sentiment-analysis-using-pytorch\n",
    "review_df_1 = pd.read_csv(\"Sephora/reviews_0-250.csv\",index_col = 0, dtype={'author_id':'str'})\n",
    "review_df_2 = pd.read_csv(\"Sephora/reviews_250-500.csv\",index_col = 0, dtype={'author_id':'str'})\n",
    "review_df_3 = pd.read_csv(\"Sephora/reviews_500-750.csv\",index_col = 0, dtype={'author_id':'str'})\n",
    "review_df_4 = pd.read_csv(\"Sephora/reviews_750-1250.csv\",index_col = 0, dtype={'author_id':'str'})\n",
    "review_df_5 = pd.read_csv(\"Sephora/reviews_1250-end.csv\",index_col = 0, dtype={'author_id':'str'})\n",
    "\n",
    "# Merge review_df_1 till review_df_6\n",
    "review_df = pd.concat([review_df_1, review_df_2, review_df_3, review_df_4, review_df_5],axis=0)\n",
    "print(\"review_df shape: \",review_df.shape)\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df['size_oz'] = product_df['size'].str.extract(r'(\\d+\\.?\\d*)\\s*oz', expand=False).astype(float)\n",
    "print(product_df[['size', 'size_oz']].sample(5))\n",
    "\n",
    "product_df['size_ml'] = product_df['size'].str.extract(r'(\\d+\\.?\\d*)\\s*mL', expand=False)\n",
    "product_df['size_ml'] = product_df['size_ml'].astype(float)\n",
    "print(product_df[['size', 'size_ml']].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df['price_per_oz'] = product_df['price_usd'] / product_df['size_oz']\n",
    "product_df['price_per_ml'] = product_df['price_usd'] / product_df['size_ml']\n",
    "product_df[['price_usd', 'size_oz', 'price_per_oz', 'size_ml', 'price_per_ml']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.kaggle.com/code/themeeemul/sephora-eda-and-sentiment-analysis-using-pytorch\n",
    "# Merge product_df and review_df\n",
    "\n",
    "# Identify overlapping columns (excluding 'product_id')\n",
    "product_df = product_df.drop(columns=['product_name', 'brand_name', 'price_usd'])\n",
    "common_cols = set(product_df.columns).intersection(set(review_df.columns)) - {'product_id'}\n",
    "\n",
    "# Add prefixes to overlapping columns to avoid conflicts\n",
    "product_df = product_df.rename(columns={col: f\"product_{col}\" for col in common_cols})\n",
    "review_df = review_df.rename(columns={col: f\"review_{col}\" for col in common_cols})\n",
    "\n",
    "# Ensure 'product_id' remains consistent in both dataframes\n",
    "if 'product_id' not in product_df.columns:\n",
    "    product_df = product_df.rename(columns={\"product_product_id\": \"product_id\"})\n",
    "if 'product_id' not in review_df.columns:\n",
    "    review_df = review_df.rename(columns={\"review_product_id\": \"product_id\"})\n",
    "\n",
    "# Retrieve non-overlapping columns from product_df\n",
    "cols_to_use = product_df.columns.difference(review_df.columns).tolist()\n",
    "cols_to_use.append('product_id')  # Ensure 'product_id' is included for merging\n",
    "\n",
    "# Merge the two datasets\n",
    "Sephora_df = pd.merge(review_df, product_df[cols_to_use], how='outer', on='product_id')\n",
    "print(\"Sephora Shape: \", Sephora_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the dataset\n",
    "\n",
    "# 1. Handle feedback-related columns\n",
    "Sephora_df = Sephora_df.assign(\n",
    "    helpfulness=Sephora_df['helpfulness'].fillna(0),\n",
    "    is_recommended=Sephora_df['is_recommended'].fillna(1)\n",
    ")\n",
    "\n",
    "# 2. Handle price-related columns by filling with price_usd\n",
    "Sephora_df = Sephora_df.assign(\n",
    "    child_max_price=Sephora_df['child_max_price'].fillna(Sephora_df['price_usd']),\n",
    "    child_min_price=Sephora_df['child_min_price'].fillna(Sephora_df['price_usd']),\n",
    "    sale_price_usd=Sephora_df['sale_price_usd'].fillna(Sephora_df['price_usd']),\n",
    "    value_price_usd=Sephora_df['value_price_usd'].fillna(Sephora_df['price_usd'])\n",
    ")\n",
    "\n",
    "# 3. Handle variation-related columns\n",
    "Sephora_df = Sephora_df.assign(\n",
    "    variation_desc=Sephora_df['variation_desc'].fillna('No variation'),\n",
    "    variation_type=Sephora_df['variation_type'].fillna('Unknown'),\n",
    "    variation_value=Sephora_df['variation_value'].fillna('Unknown')\n",
    ")\n",
    "\n",
    "# 4. Handle product and review metadata\n",
    "Sephora_df = Sephora_df.assign(\n",
    "    review_text=Sephora_df['review_text'].fillna('No review provided'),\n",
    "    review_title=Sephora_df['review_title'].fillna('No title'),\n",
    "    tertiary_category=Sephora_df['tertiary_category'].fillna('Uncategorized')\n",
    ")\n",
    "\n",
    "# 5. Handle skin, hair, and eye attributes\n",
    "Sephora_df = Sephora_df.assign(\n",
    "    skin_tone=Sephora_df['skin_tone'].fillna('Not specified'),\n",
    "    eye_color=Sephora_df['eye_color'].fillna('Not specified'),\n",
    "    skin_type=Sephora_df['skin_type'].fillna('Not specified'),\n",
    "    hair_color=Sephora_df['hair_color'].fillna('Not specified')\n",
    ")\n",
    "\n",
    "# 6. Handle ingredient and highlight columns\n",
    "Sephora_df = Sephora_df.assign(\n",
    "    ingredients=Sephora_df['ingredients'].fillna('Ingredients not listed'),\n",
    "    highlights=Sephora_df['highlights'].fillna('No highlights available')\n",
    ")\n",
    "\n",
    "# 7. Handle size-related columns\n",
    "Sephora_df = Sephora_df.assign(\n",
    "    size=Sephora_df['size'].fillna('Unknown size'),\n",
    "    size_ml=Sephora_df['size_ml'].fillna(Sephora_df['size_ml'].median()),\n",
    "    size_oz=Sephora_df['size_oz'].fillna(Sephora_df['size_oz'].median())\n",
    ")\n",
    "\n",
    "# 8. Handle price per unit columns\n",
    "Sephora_df = Sephora_df.assign(\n",
    "    price_per_ml=Sephora_df['price_per_ml'].fillna(Sephora_df['price_per_ml'].median()),\n",
    "    price_per_oz=Sephora_df['price_per_oz'].fillna(Sephora_df['price_per_oz'].median())\n",
    ")\n",
    "\n",
    "# 9. Print the result to confirm the missing values have been handled\n",
    "missing_counts_after = Sephora_df.isna().sum()\n",
    "print(\"Missing values after processing:\")\n",
    "print(missing_counts_after[missing_counts_after > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows without review_rating information for analysis convenience\n",
    "Sephora_df = Sephora_df.dropna(subset=['review_rating'])\n",
    "\n",
    "# Print the result to confirm the missing values have been handled\n",
    "missing_counts_after = Sephora_df.isna().sum()\n",
    "print(\"Missing values after processing:\")\n",
    "print(missing_counts_after[missing_counts_after > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conduct effective analysis, we need to retain intrinsic user characteristics. Therefore, we will remove features such as `is_recommended` and `helpfulness`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['is_recommended', 'helpfulness', 'review_text', 'review_title', 'submission_time', \\\n",
    "    'total_feedback_count', 'total_neg_feedback_count', 'total_pos_feedback_count']\n",
    "Sephora_df = Sephora_df.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns2 = ['size', 'size_ml']\n",
    "Sephora_df = Sephora_df.drop(columns=drop_columns2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of Sephora: \", Sephora_df.shape)\n",
    "Sephora_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sephora_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['review_rating']\n",
    "id_cols = ['author_id', 'product_id', 'brand_id']\n",
    "numerical_features = ['price_usd', 'child_count', 'child_max_price', 'child_min_price', \n",
    "                    'loves_count','price_per_ml', 'price_per_oz', 'product_rating', \n",
    "                    'reviews', 'sale_price_usd', 'size_oz', 'value_price_usd']\n",
    "categorical_features = ['skin_tone', 'eye_color', 'skin_type', 'hair_color', 'new', \n",
    "                        'online_only', 'out_of_stock', 'sephora_exclusive',\n",
    "                        'limited_edition']\n",
    "text_cols = ['product_name', 'variation_desc', 'variation_type', 'variation_value',\n",
    "             'highlights', 'secondary_category', 'tertiary_category', 'ingredients',\n",
    "             'brand_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code generation by ChatGPT\n",
    "\n",
    "# Update matplotlib parameters for tighter layouts\n",
    "plt.rcParams.update({\n",
    "    'figure.autolayout': True,\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.labelsize': 12,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'figure.constrained_layout.use': True\n",
    "})\n",
    "\n",
    "\n",
    "def plot_categorical_distribution_by_target(df, column, target=\"Transported\", palette=\"Set2\"):\n",
    "    \"\"\"\n",
    "    Plot the distribution of a categorical variable, grouped by the target variable in a 1-row, 2-column layout.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The dataset.\n",
    "    column (str): The categorical column to visualize.\n",
    "    target (str): The target variable to group by.\n",
    "    palette (str): The color palette to use.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Extract unique categories and sort them by their first letter\n",
    "    categories = df[column].dropna().unique()\n",
    "    sorted_categories = sorted(categories, key=lambda x: str(x)[0])\n",
    "    \n",
    "    target_values = df[target].unique()\n",
    "    if isinstance(target_values[0], np.float64):\n",
    "        target_values = sorted(target_values)\n",
    "    colors = sns.color_palette(palette, n_colors=len(target_values))\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(18, 4), sharey=False)  # 5 columns per row\n",
    "    \n",
    "    for i, value in enumerate(target_values):\n",
    "        sns.countplot(\n",
    "            data=df[df[target] == value],\n",
    "            x=column,\n",
    "            order=sorted_categories,  # Pass the sorted order here\n",
    "            hue=None,\n",
    "            color=colors[i],\n",
    "            ax=axes[i]\n",
    "        )\n",
    "        axes[i].set_title(f\"{target} = {value}\")\n",
    "        axes[i].set_xlabel(column)\n",
    "        axes[i].set_ylabel(\"Count\" if i == 0 else \"\")\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.suptitle(f\"Distribution of {column} by {target}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_numeric_distribution_by_target(df, column, target=\"Transported\", bins=20, kde=True, palette=\"Set2\"):\n",
    "    \"\"\"\n",
    "    Plot the distribution of a numeric variable, grouped by the target variable in a 1-row, 2-column layout.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The dataset.\n",
    "    column (str): The numeric column to visualize.\n",
    "    target (str): The target variable to group by.\n",
    "    bins (int): Number of bins for the histogram.\n",
    "    kde (bool): Whether to show a KDE plot.\n",
    "    palette (str): The color palette for different target values.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    target_values = df[target].unique()\n",
    "    if isinstance(target_values[0], np.float64):\n",
    "        target_values = sorted(target_values)\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(18, 4), sharey=False)  # 5 columns per row\n",
    "    colors = sns.color_palette(palette, n_colors=len(target_values))\n",
    "    for i, value in enumerate(target_values):\n",
    "        sns.histplot(\n",
    "            df[df[target] == value][column].dropna(),\n",
    "            bins=bins,\n",
    "            kde=kde,\n",
    "            ax=axes[i],\n",
    "            color=colors[i],\n",
    "            alpha=0.7\n",
    "        )\n",
    "        axes[i].set_title(f\"{target} = {value}\")\n",
    "        axes[i].set_xlabel(column)\n",
    "        axes[i].set_ylabel(\"Frequency\" if i == 0 else \"\")\n",
    "    plt.suptitle(f\"Distribution of {column} by {target}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_correlation_heatmap(df, target=\"Transported\"):\n",
    "    \"\"\"\n",
    "    Plot a heatmap of correlations between numeric variables, with respect to the target variable.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The dataset.\n",
    "    target (str): The target variable.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    numeric_cols = df.select_dtypes(include=[\"float64\", \"int64\", \"bool\"]).drop(columns=[\"PassengerId\"], errors=\"ignore\")\n",
    "    correlation_matrix = numeric_cols.corr()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "    plt.title(\"Correlation Heatmap of Numeric Features\")\n",
    "    plt.show()\n",
    "\n",
    "def visualize_sephora_data_by_target(df, categorical_features, numerical_features, target=\"Transported\"):\n",
    "    \"\"\"\n",
    "    Visualize the dataset by target, with categorical and numeric distributions shown side by side.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The dataset.\n",
    "    target (str): The target variable.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Plot categorical features\n",
    "    for feature in categorical_features:\n",
    "        plot_categorical_distribution_by_target(df, column=feature, target=target)\n",
    "    \n",
    "    # Plot numeric features\n",
    "    for feature in numerical_features:\n",
    "        plot_numeric_distribution_by_target(df, column=feature, target=target, bins=20, kde=True, palette=\"Set2\")\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    plot_correlation_heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_sephora_data_by_target(Sephora_df, categorical_features, numerical_features, target=\"review_rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical Features - Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Log Transformation to several numeric features and visualize the changes\n",
    "# Use ChatGPT to facilitate data transformation\n",
    "\n",
    "def apply_log_transformation(df, features):\n",
    "    \"\"\"\n",
    "    Apply log transformation to specified numeric features in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame.\n",
    "    features (list): List of column names to log transform.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with log-transformed features.\n",
    "    \"\"\"\n",
    "    df_transformed = df.copy()\n",
    "    for feature in features:\n",
    "        if feature in df_transformed.columns:\n",
    "            # Apply log1p to handle zeros\n",
    "            df_transformed[feature] = np.log1p(df_transformed[feature])\n",
    "        else:\n",
    "            print(f\"Feature '{feature}' not found in DataFrame.\")\n",
    "    return df_transformed\n",
    "\n",
    "def apply_sqrt_transformation(df, features):\n",
    "    \"\"\"\n",
    "    Apply square root transformation to specified numeric features in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame.\n",
    "    features (list): List of column names to apply square root transformation.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with square root-transformed features.\n",
    "    \"\"\"\n",
    "    df_transformed = df.copy()\n",
    "    for feature in features:\n",
    "        if feature in df_transformed.columns:\n",
    "            # Apply sqrt transformation, ensure non-negative values\n",
    "            df_transformed[feature] = np.sqrt(df_transformed[feature].clip(lower=0))\n",
    "        else:\n",
    "            print(f\"Feature '{feature}' not found in DataFrame.\")\n",
    "    return df_transformed\n",
    "\n",
    "\n",
    "def visualize_features(df, features, bins=20):\n",
    "    \"\"\"\n",
    "    Visualize the distributions of specified features in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame.\n",
    "    features (list): List of column names to visualize.\n",
    "    bins (int): Number of bins for the histograms.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(\"Visualizing features...\")\n",
    "    print(features + [\"review_rating\"])\n",
    "    visualize_sephora_data_by_target(df[features + [\"review_rating\"]], categorical_features=[], \\\n",
    "        numerical_features=features, target=\"review_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log transformation\n",
    "\n",
    "features_to_transform = ['child_max_price', 'child_min_price', 'product_rating', \n",
    "                    'reviews', 'loves_count', 'price_usd', 'price_per_ml',\n",
    "                    'price_per_oz', 'sale_price_usd', 'value_price_usd']\n",
    "\n",
    "Sephora_df = apply_log_transformation(Sephora_df, features_to_transform)\n",
    "\n",
    "# Visualize transformed features\n",
    "print(\"Log Transformed Features:\")\n",
    "visualize_features(Sephora_df, features_to_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category Features - One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_features(df, categorical_features):\n",
    "    \"\"\"\n",
    "    Perform one-hot encoding for a list of categorical features in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    categorical_features (list): A list of categorical column names to one-hot encode.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with the specified categorical features one-hot encoded.\n",
    "    \"\"\"\n",
    "    # Perform one-hot encoding for the categorical features\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['skin_tone', 'eye_color', 'skin_type', 'hair_color', 'new', \n",
    "                        'online_only', 'out_of_stock', 'sephora_exclusive',\n",
    "                        'limited_edition']\n",
    "Sephora_df[categorical_features] = Sephora_df[categorical_features].astype('category')\n",
    "Sephora_df = one_hot_encode_features(Sephora_df, categorical_features)\n",
    "\n",
    "# Check the result\n",
    "print(\"Original DataFrame shape:\", Sephora_df.shape)\n",
    "print(\"Encoded DataFrame shape:\", Sephora_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Features - TF-IDF Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_svd_transform(df, text_columns, n_components=100, max_features=1000):\n",
    "    \"\"\"\n",
    "    Perform TF-IDF transformation on specified text columns and apply SVD for dimensionality reduction.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    text_columns (list): List of column names containing text data.\n",
    "    n_components (int): Number of components for SVD.\n",
    "    max_features (int): Maximum number of features for TF-IDF vectorization.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with reduced dimensions after SVD.\n",
    "    \"\"\"\n",
    "    tfidf_vectorizers = {}\n",
    "    tfidf_results = []\n",
    "    \n",
    "    # Perform TF-IDF on each text column\n",
    "    for col in text_columns:\n",
    "        vectorizer = TfidfVectorizer(max_features=max_features, stop_words='english')\n",
    "        tfidf_matrix = vectorizer.fit_transform(df[col].fillna(\"\"))  # Handle NaN by filling with empty strings\n",
    "        tfidf_vectorizers[col] = vectorizer\n",
    "        tfidf_results.append(tfidf_matrix)\n",
    "\n",
    "    # Concatenate all TF-IDF matrices\n",
    "    combined_tfidf = np.hstack([result.toarray() for result in tfidf_results])\n",
    "\n",
    "    # Apply SVD for dimensionality reduction\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "    reduced_matrix = svd.fit_transform(combined_tfidf)\n",
    "\n",
    "    # Return as a DataFrame for interpretability\n",
    "    svd_columns = [f\"svd_component_{i+1}\" for i in range(n_components)]\n",
    "    return pd.DataFrame(reduced_matrix, columns=svd_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = ['product_name', 'variation_desc', 'variation_type', 'variation_value',\n",
    "             'highlights', 'secondary_category', 'tertiary_category', 'ingredients',\n",
    "             'brand_name']\n",
    "reduced_df = tfidf_svd_transform(Sephora_df, text_cols, n_components=50, max_features=500)\n",
    "\n",
    "# Check the reduced DataFrame\n",
    "print(reduced_df.shape)\n",
    "print(reduced_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
